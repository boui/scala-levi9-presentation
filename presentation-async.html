    <!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>Being asynchronous</title>

    <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
    <meta name="author" content="Hakim El Hattab">

    <meta name="apple-mobile-web-app-capable" content="yes"/>
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="css/reveal.min.css">
    <link rel="stylesheet" href="css/theme/default.css" id="theme">

    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- If the query includes 'print-pdf', use the PDF print sheet -->
    <script>
        document.write('<link rel="stylesheet" href="css/print/' + ( window.location.search.match(/print-pdf/gi) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">');
    </script>

    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
</head>
<body>
<div class="reveal">
<div class="slides">
<section>
    <h2>Concurrent, Asynchronous, Efficient</h2>
    <h2>beautiful</h2>

    <div >
        <img src="img/reef.jpg"/>
    </div>
    <div class="absolute-element"
         style="position: absolute; width: 314px; height: 46px; z-index: 4; left: 321px; top: 567px;">
        <h3>by Roksana Seletska, Levi9</h3>
        <br>
    </div>
</section>
<section>
    <section>
        <h1>About me</h1>
        <h2>Rocksy seletska</h2>
        <div style="float:left ;padding-left:10%">
            <img src="img/me1.jpg" height="250px" />
            <h4>Software engineer</h4>
            <h4>Scala  JS  Go </h4>
        </div>
        <div >
            <img src="img/triggerfish.jpg" height="250px" />
            <h4>Open water diver</h4>
        </div>
        <div>
            <h4>mail to: rocksyseletska2837@gmail.com</h4>
        </div>
    </section>
    <section>
        <h3>Previous talk</h3>
        <h3><a href="https://github.com/boui/scala-levi9-presentation">Scala intro, monads</a></h3>
        <text>open /presentation.html</text>
    </section>
</section>
<section> 
    <h1> Major spoiler</h1>
    <h3> It is not about shared mutable state!</h3>
    <h3 class="fragment"> We won't be talking about semaphores, mutexes, monitors or locks</h3>
    <h3 class="fragment"> Well, maybe a bit</h3>
</section>
<section>     
    <img src="img/omg1.jpg" /> 
</section>
<section>
   <section>
       <h2>What is sad about concurrency?</h2>
       <div class="fragment">
            <h2 >Concurrent doesn't mean parallel</h2>
            <img src="img/sad_panda_painting.jpg" height="150px" />
        </div>
        <h4 class="fragment">Concurrent execution only means soma amount of tasks to be executed in some time frame</h4>
        <h4 class="fragment">... but not neccesary at the same time</h4>
   </section>
   <section>
        <h4><span style="color:#4477AA">Concurrency</span> starts when you don't have enough cores for each process/thread</h4>        
        <text class="fragment" style="color:red">It hurts.</text>
    </section>
</section>
<section>
    <section>
        <h1> Native threads </h1>
        <div>
            <h4 class="fragment"> Managed by OS, so this 'managment' implementation heavily depends on OS</h4>
            <h4 class="fragment"> Kernel-level sync on critical sections </h4>
            <h4 class="fragment"> Really supports multiple CPUs <br/> if a system has n CPUs, then up to n threads can run simultaneously </h4>
        </div>
    </section>
    <section>
            <div >
                <h2> Pre-emptive scheduling </h2>
                <img class="fragment" src="img/pre.png"/>
            </div>
            <h4 class="fragment"> Scheduler has prioraized queue of threads and switches time to time</h4>
    </section>
    <section>
        <div> 
            <h2>Time slice or quantum</h2>
                <text class="fragment">The scheduler is run once every time slice to choose the next process to run</text>
            <h2> Context switch </h2>
            <ul>
                <li class="fragment">Decide whether to do a context switch</li>
                <li class="fragment">Save process with context</li>
                <li class="fragment">Find best process to execute</li>
                <li class="fragment">Restore context</li>
            </ul>
        </div>
    </section>   
    <section>
        <h2>Trap(int 0x80)</h2>
        <img src="img/flow.png" height="500px" />
    </section>
    <section> 
        <h2>Summary </h2>
        <h4 class="fragment"> Threads may be executed parallel </h4>
        <h4 class="fragment"> Switching is really heavy, critical section means major bottleneck</h4>
        <h4 class="fragment"> Thread will be interrupted on time slice end </h4>
        <h4 class="fragment"> Scheduler and theads amount limit is OS dependent</h4>
    </section>
</section>
<section>
    <section>
        <h4>is it deep enough?</h4>
        <img src="img/we_must_go_deeper.jpg"/>
    </section>
    <section>
        <h2> Non preemptive multitasking</h2>
        <img class="fragment" src="img/coop.png"/>
    </section>
    <section>
        <h1>Green threads</h1>
        <h4 class="fragment"> It is run as one native thread! </h4>
        <h4 class="fragment"> Yet, it can be concurrent </h4>
        <h4 class="fragment"> Scheduling and switching is managed by Virtual Machine or lib </h4>
        <h4 class="fragment"> Quite deterministic scheduling, language dependent </h4>
        <h4 class="fragment"> Lightweight since no kernel objects are created </h4>
        <h4 class="fragment"> Large number of threads can be started </h4>
    </section>
    <section>
        <h1>Goals</h1>
        <h3 class="fragment">Small memory footpint</h3>
        <h4 class="fragment" style="color:#4477AA">Memory size is a parameter to VM or library</h4>

        <h3 class="fragment">Controllable switching</h3>
        <h4 class="fragment" style="color:#4477AA">Here were scheduler concept appears</h4>

        <h3 class="fragment">Is easy to create</h3>
        <h4 class="fragment" style="color:#4477AA">You only need to reserve memory and being put into scheduler queue</h4>
    </section>
</section>
<section>
    <section>
        <h2> Greenlets - Python</h2>
        <img src="img/py.png"/>
        <h4 class="fragment"> Not a native feature of a language</h4>    
        <h4 class="fragment"> Pretty low level</h4>    
        <h4 class="fragment"> Based on coroutines</h4>
    </section>
    <section>       
        <h2>Generator</h2>
        <h4 class="fragment">Intended to generate values on demand </h4>
        <pre>
             <code class="python">
def get_primes(number):
    while True:
        if is_prime(number): #you know how to check it, right?
            yield number
        number += 1
#Example of usage
primes_up_to_2000 = for next_prime in get_primes(3) 
    if next_prime > 2000 return
#Result [1,2,3,5,7,11...]
             </code>
        </pre>
    </section>
    <section>
        <h2>Coroutine</h2>
        <h4 class="fragment">Intended to consume values</h4>
        <pre>
             <code class="python">
def grep(pattern):
        print "Looking for %s" % pattern
        while True:
            line = (yield)
            if pattern in line:
                print line,

g = grep("python")
# Notice how you don't need a next() call here
g.send("Yeah, but no, but yeah, but no")
g.send("A series of tubes")
g.send("python generators rock!") # this will be printed
             </code>
        </pre>
    </section>
    <section>
        <h4>Pipeline masterpiece</h4>
        <pre>
            <code class="python">
def follow(thefile, target):
thefile.seek(0,2)      # Go to the end of the file
while True:
     line = thefile.readline()
     if not line:
         time.sleep(0.1)    # Sleep briefly
         continue
     target.send(line)

# A filter.
@coroutine
def grep(pattern,target):
    while True:
        line = (yield)           # Receive a line
        if pattern in line:
            target.send(line)    # Send to next stage

# A sink.  A coroutine that receives data
@coroutine
def printer():
    while True:
         line = (yield)
         print line,

# Broadcast a stream onto multiple targets
@coroutine
def broadcast(targets):
    while True:
        item = (yield)
        for target in targets:
            target.send(item)

# Example use
if __name__ == '__main__':
    f = open("access-log")
    p = printer()
    follow(f,
       broadcast([grep('python',p),
                  grep('ply',p),
                  grep('swig',p)])
           )
        </code>
    </pre>
    </section>
    <section>
        <h2>Greenlet</h2>
        <pre>
            <code class="python">
from greenlet import greenlet

def test1():
    print 12
    gr2.switch()
    print 34

def test2():
    print 56
    gr1.switch()
    print 78

gr1 = greenlet(test1)
gr2 = greenlet(test2)
gr1.switch()  
            </code>
        </pre>
    </section>
    <section>
        <h4>Cooperative multitasking on coroutines is as simple as this:</h4>
        <h4>We know exactly when coroutine ends, on yield</h4>
        <h4>When it happens scheduler just selects a next coroutine to be executed</h4>
    </section>
    <section>
        <pre>
            <code class="python">
#class to incapsulate coroutine itself with meta and target coroutine
#Coroutines shouldn't create a loop
class Task(object): 
    taskid = 0
    def __init__(self,target):
        Task.taskid += 1
        self.tid     = Task.taskid   # Task ID
        self.target  = target        # Target coroutine
        self.sendval = None          # Value to send

    # Run a task until it hits the next yield statement
    def run(self):
        return self.target.send(self.sendval)
            </code>
        </pre>
    </section>
    <section>
        <pre>
            <code class="python">
#Deterministic scheduler            
class Scheduler(object):
    def __init__(self):
        self.ready   = Queue()   
        self.taskmap = {}        

    def new(self,target): #create new task and schedule it
        newtask = Task(target)
        self.taskmap[newtask.tid] = newtask
        self.schedule(newtask)
        return newtask.tid

    def schedule(self,task):
        self.ready.put(task)

    #start scheduling
    def mainloop(self):
        while self.taskmap:
            task = self.ready.get()
            result = task.run()
            self.schedule(task)
            </code>
        </pre>
    </section>
    <section>
        <pre>
            <code class="python">
# ------------------------------------------------------------
#                      === Example ===
# ------------------------------------------------------------
 # Two tasks
    def foo():
        while True:
            print "I'm foo"
            yield

    def bar():
        while True:
            print "I'm bar"
            yield    
        
    # Run them
    sched = Scheduler()
    sched.new(foo())
    sched.new(bar())
    sched.mainloop()

# i'm foo
# i'm bar
            </code>
        </pre>
    </section>
</section>
<section>
    <section>
        <h2>Goroutines, Go</h2>
        <div style="font-size:14px">it is gopher</div>
        <img src="img/go.png"/>
        <h4 class="fragment">Goroutines are also coop-multitasking</h4>
        <h4 class="fragment">Original language feature</h4>
        <h4 class="fragment">Motivation - i still want parallelism!</h4>
        <h4 class="fragment">Goroutines multiplexes on OS threads, so even if any will be block, other goroutines can still be executed</h4>
    </section>
    <section>
    <pre>
        <code class="go">
func f(from string) {
    for i := 0; i < 3; i++ {
        fmt.Println(from, ":", i)
    }
}

func main() {

    // Suppose we have a function call `f(s)`. Here's how
    // we'd call that in the usual way, running it
    // synchronously.
    f("direct")

    // To invoke this function in a goroutine, use
    // `go f(s)`. This new goroutine will execute
    // concurrently with the calling one.
    go f("goroutine")

    // You can also start a goroutine for an anonymous
    // function call.
    go func(msg string) {
        fmt.Println(msg)
    }("going")

    // Our two goroutines are running asynchronously in
    // separate goroutines now, so execution falls through
    // to here. This `Scanln` code requires we press a key
    // before the program exits.
    var input string
    fmt.Scanln(&input)
    fmt.Println("done")
}
</code>
</pre>
    </section>
    <section>
        <h2>Goroutine scheduling points</h2>
        <h4 class="fragment">Channel sending and receiving</h4>
        <h4 class="fragment">Calling another goroutine</h4>
        <h4 class="fragment">Blocking syscall</h4>
        <h4 class="fragment">Garbage collection</h4>
    </section>
    <section>
        <h2>Multiplexing</h2>
        <h4 class="fragment">At any call to the operating system the call to entersyscall informs the runtime that this thread is about to block </h4>
        <h4 class="fragment">Runtime spinnes up a new thread which will service other goroutines while this current thread blocked.</h4>
        <h4 class="fragment">So Go process contains OS threads</h4>
        <h4 class="fragment">Go runtime taking care of assigning a runnable Goroutine to a free operating system thread</h4>
    </section>
    <section>
        <h2>Channels</h2>
        <h4>Goroutines can be sending each other messages</h4>
        <h4>Channels send/receive is synchronous</h4>
        <h4>But channel can be buffered, and it becomes more like mailbox in actor</h4>
        <h4>Chanels are also able to be multiplexed, chained and much more</h4>
    </section>
    <section>
        <h3>Lets check out how easy is this thing to use</h3>
        

    </section>
</section>
<section>
    <h1>Javascript Event loop </h1>
</section>
<section>
    <section>
        Continuation passing style
    </section>
    <section>
        <h2> Futures </h2>
        <h4 class="fragment"> Future is a function executed in another thread which results with result</h4>
        <h4 class="fragment"> result may be either success or an error </h4>
        <h4 class="fragment"> Success means future return a value, error - exception occurred or business logic failed </h4>
    </section>
    <section>
        <h2> Promises </h2>
        <h4 class="fragment"> Are a way future acknowledge each other about results </h4>
        <h4 class="fragment"> Futures can subscribe to promises to be executed one by one </h4>
        <h4 class="fragment"> Within promises futures can be explicitly controlled </h4>
    </section>
</section>
<section>
    <h2>Agent</h2>
</section>
<section>
    <section>
        <h2> Actor</h2>
        <h4> Actors are based on green threads, so actors are lightweight.</h4>
        <h4> What makes thing an actor:</h4>
        <h4 class="fragment">Inner state</h4>
        <h4 class="fragment">Messages queue</h4>   
        <h4 class="fragment">Message handling code</h4>
    </section>
    <section>
        <h2> Actors can be used to control complex asynchronous flows within messages </h2>
        <h2> Actors are good if you have a state, that needs to be managed </h2>
        <h2> Actors are good for distributed systems </h2>
        <h2> Actors can produce actors hierarchies </h2>
        <h2> Actors are an explicit way to manage mutable state </h2>
    </section>
    <section>
        <h2>Rules of an actor</h2>
        <h4 class="fragment"> Never do a timeconsuming tasks</h4>
        <h4 class="fragment"> Messages are immutable </h4>
        <h4 class="fragment"> Avoid system starvation(throttling) </h4>
    </section>
    <section>
        <h2> Scala rules of an actor</h2>
        <h4> Use futures for timeconsuming tasks </h4>
        <h4> Use actor states to handle errors </h4>
        <h4> Don't forget that 'self' is a method </h4>
        <h4> Manage throttling carefully, since it might happen </h4>
        <h4> Manage resource usage </h4>
    </section>
</section>
<section>
    <h2>Demo</h2>
</section>
</div>
</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.min.js"></script>

<script>

    // Full list of configuration options available here:
    // https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,

        theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
        transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

        // Parallax scrolling
        // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
        // parallaxBackgroundSize: '2100px 900px',

        // Optional libraries used to extend on reveal.js
        dependencies: [
            { src: 'lib/js/classList.js', condition: function () {
                return !document.body.classList;
            } },
            { src: 'plugin/markdown/marked.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            } },
            { src: 'plugin/markdown/markdown.js', condition: function () {
                return !!document.querySelector('[data-markdown]');
            } },
            { src: 'plugin/highlight/highlight.js', async: true, callback: function () {
                hljs.initHighlightingOnLoad();
            } },
            { src: 'plugin/zoom-js/zoom.js', async: true, condition: function () {
                return !!document.body.classList;
            } },
            { src: 'plugin/notes/notes.js', async: true, condition: function () {
                return !!document.body.classList;
            } }
        ]
    });

</script>
</body>
</html>



